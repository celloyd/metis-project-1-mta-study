{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "pd.set_option('display.max_rows', 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in october 2019 mta data\n",
    "df1 = pd.read_csv('http://web.mta.info/developers/data/nyct/turnstile/turnstile_191026.txt')\n",
    "df2 = pd.read_csv('http://web.mta.info/developers/data/nyct/turnstile/turnstile_191019.txt')\n",
    "df3 = pd.read_csv('http://web.mta.info/developers/data/nyct/turnstile/turnstile_191012.txt')\n",
    "df4 = pd.read_csv('http://web.mta.info/developers/data/nyct/turnstile/turnstile_191005.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframes = [df1, df2, df3, df4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_dfs_add_time(dataframe_list):\n",
    "    \"\"\"\n",
    "    feed in a list of turnstyle dataframes\n",
    "    returns the combined datafrae with columns for date time and day of week\n",
    "    \"\"\"\n",
    "    # concatenate the dataframes into one\n",
    "    df = pd.concat(dataframe_list, ignore_index=True)\n",
    "    \n",
    "    # rename the exits field\n",
    "    df = df.rename(columns={'EXITS                                                               ': 'EXITS'})\n",
    "    \n",
    "    # create a new column that combines the day and time into one and makes it a datetime object\n",
    "    df[\"DATE_TIME\"] =  pd.to_datetime(df[\"DATE\"] +\" \"+ df[\"TIME\"])\n",
    "    \n",
    "    # add in a day of the week column\n",
    "    df[\"DAY_INT\"] = df[\"DATE_TIME\"].dt.dayofweek\n",
    "    \n",
    "    # create a mapper to map the day of the week nubers to actual string values\n",
    "    day_dict = {\n",
    "        0: 'Monday',\n",
    "        1: 'Tuesday',\n",
    "        2: 'Wednesday',\n",
    "        3: 'Thursday',\n",
    "        4: 'Friday',\n",
    "        5: 'Saturday',\n",
    "        6: 'Sunday'\n",
    "    }\n",
    "    \n",
    "    # add that day of the week string column\n",
    "    df[\"DAY_STR\"] = df[\"DAY_INT\"].map(day_dict)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_df = combine_dfs_add_time(dataframes)\n",
    "combined_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_entry_and_exit_differences(df):\n",
    "    \"\"\"\n",
    "    Takes in the dataframe with the date time column\n",
    "    returns a data frame with a entry and exit diff column\n",
    "    these new columns tell us how many people exuted/entered in that time period\n",
    "    \"\"\"\n",
    "    \n",
    "    # sort the dataframe by turnstyle date\n",
    "    ordered_date_df = df.sort_values(by=['STATION', 'SCP','UNIT','C/A', 'DATE_TIME'])\n",
    "    \n",
    "    \"\"\"\n",
    "    group by station, scp, unit, and c/a to get the individual counters \n",
    "    then take the difference in entries to get entry changes on each timestamp\n",
    "    \"\"\"\n",
    "    ordered_date_df['ENTRIES_DIFF']=ordered_date_df.groupby(['STATION', 'SCP','UNIT','C/A'])['ENTRIES'].diff().fillna(0)\n",
    "    \n",
    "    \"\"\"\n",
    "    group by station, scp, unit, and c/a to get the individual counters \n",
    "    then take the difference in exits to get exit changes on each timestamp\n",
    "    \"\"\"\n",
    "    ordered_date_df['EXIT_DIFF']=ordered_date_df.groupby(['STATION', 'SCP', 'UNIT', 'C/A'])['EXITS'].diff().fillna(0)\n",
    "    \n",
    "    return ordered_date_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_df = add_entry_and_exit_differences(combined_df)\n",
    "combined_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_entry_exit_values(df, max_val, min_val=0):\n",
    "    \"\"\"\n",
    "    takes in a dataframe with the entry/exit diff columns and a max and min val for the entry diff\n",
    "    returns a dataframe with the crazy values removed\n",
    "    \"\"\"\n",
    "    \n",
    "    # create mask to remove negative entries and exits or astronomically high differences\n",
    "    pre_cleaning_rows = df.shape[0]\n",
    "    cleaning_mask = (df[\"ENTRIES_DIFF\"]>=min_val) & \\\n",
    "                    (df[\"EXIT_DIFF\"]>=min_val) & \\\n",
    "                    (df[\"ENTRIES_DIFF\"]<max_val) & \\\n",
    "                    (df[\"EXIT_DIFF\"]<max_val)\n",
    "    \n",
    "    df = df[cleaning_mask]\n",
    "    post_cleaning_rows = df.shape[0]\n",
    "    print(\"You removed {} rows in the cleaning\".format(pre_cleaning_rows-post_cleaning_rows))\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_df=clean_entry_exit_values(combined_df, 100000)\n",
    "combined_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def totals_combined_per_station(df):\n",
    "    \n",
    "    \"\"\"\n",
    "    takes in a dataframe with the entry/exit diff columns\n",
    "    returns a dataframe with rows of total entries, exits, and cobined for each station in desc order\n",
    "    \"\"\"\n",
    "    \n",
    "    # show the total entries and exits, it looks much better\n",
    "    entries_exit_totals = df.groupby([\"STATION\"])[[\"ENTRIES_DIFF\", \"EXIT_DIFF\"]].sum()\n",
    "    \n",
    "    # cobine the entries and exits and sort to get the most popuklar stations\n",
    "    entries_exit_totals[\"COMBINED\"] = entries_exit_totals[\"ENTRIES_DIFF\"] + entries_exit_totals[\"EXIT_DIFF\"]\n",
    "    entries_exit_totals = entries_exit_totals.sort_values(by=[\"COMBINED\"], ascending=False)\n",
    "    \n",
    "    return entries_exit_totals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "daily_totals = totals_combined_per_station(combined_df)\n",
    "daily_totals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def avg_per_day_of_week(df):\n",
    "    \"\"\"\n",
    "    takes in a dataframe with the entry/exit diff columns\n",
    "    returns a dataframe with rows of total entries, exits, and cobined for the avg traffic \n",
    "    on each DAY OF WEEK for each station\n",
    "    \n",
    "    i.e. Station A on Monday\n",
    "    \"\"\"\n",
    "    \n",
    "    # return the avg usage per day of week per station on each day\n",
    "    total_daily_per_station = df.groupby(['STATION', 'DATE', 'DAY_STR'])[\"ENTRIES_DIFF\", \"EXIT_DIFF\"].sum()\n",
    "\n",
    "    # average out the traffic at each station grouped by day of the week \n",
    "    avg_daily_per_station = total_daily_per_station.groupby([\"STATION\", \"DAY_STR\"])[\"ENTRIES_DIFF\", \"EXIT_DIFF\"].mean()\n",
    "\n",
    "    # cobine the entries and exits and sort to get the most popuklar days at what stations \n",
    "    avg_daily_per_station[\"COMBINED\"] = avg_daily_per_station[\"ENTRIES_DIFF\"] + avg_daily_per_station[\"EXIT_DIFF\"]\n",
    "    avg_daily_per_station.sort_values(by=[\"COMBINED\"], ascending=False)\n",
    "    \n",
    "    return avg_daily_per_station\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_per_day = avg_per_day_of_week(combined_df)\n",
    "avg_per_day.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def avg_per_day_of_week_and_time(df):\n",
    "    \"\"\"\n",
    "    takes in a dataframe with the entry/exit diff columns\n",
    "    returns a dataframe with rows of total entries, exits, and cobined for the avg traffic \n",
    "    on each DAY OF WEEK and TIME SLOT for each station\n",
    "    \n",
    "    i.e. Station A on Monday between 2-6 pm\n",
    "    \"\"\"\n",
    "    \n",
    "    # get the total traffic for each station at each hour of each day\n",
    "    total_hourly_per_station = df.groupby(['STATION', 'DATE', 'DAY_STR' ,'TIME'])[\"ENTRIES_DIFF\", \"EXIT_DIFF\"].sum()\n",
    "\n",
    "    # average out the traffic at each station grouped by day of the week and time slot\n",
    "    avg_hourly_per_station = total_hourly_per_station.groupby([\"STATION\", 'DAY_STR' ,\"TIME\"])[\"ENTRIES_DIFF\", \"EXIT_DIFF\"].mean()\n",
    "\n",
    "    # cobine the entries and exits and sort to get the most popular days and times at each stations \n",
    "    avg_hourly_per_station[\"COMBINED\"] = avg_hourly_per_station[\"ENTRIES_DIFF\"] + avg_hourly_per_station[\"EXIT_DIFF\"]\n",
    "    avg_hourly_per_station.sort_values(by=[\"COMBINED\"], ascending=False).head(50)\n",
    "    \n",
    "    return avg_hourly_per_station"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_per_day_of_week_and_time = avg_per_day_of_week_and_time(combined_df)\n",
    "avg_per_day_of_week_and_time.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
